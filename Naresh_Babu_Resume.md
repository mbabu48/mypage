<H2> Naresh Babu Makkena  </H2>

**CONTACT** <br>
    [officialmail.naresh@gmail.com](mailto:officialmail.naresh@gmail.com) </br>	
    (804) 528-6353 </br>
    [linkedin:naresh babu makkena](https://www.linkedin.com/in/naresh-babu-makkena/) 

---

**PROFESSIONAL SUMMARY**

**A Principal Architect with 14+ years of experience leading enterprise-wide AI/ML and Generative AI transformations, building scalable, cloud-native platforms that drive innovation and business value.**

* **Strategic AI/ML Leader:** Highly accomplished leader in setting AI/ML strategic direction for the organization. Experienced in leading the design and delivery of scalable, resilient, cloud-native platforms, specializing in Generative AI and Machine Learning applications.  
* **Deep Cloud & GenAI Platform Expertise:** Proven expert in building comprehensive end-to-end cloud-native (AWS, GCP, Azure), traditional Machine Learning, and Generative AI platforms, utilizing CPU and GPU accelerated compute for training and deployment.  
* **Platform Architecture Proficiency:** Renowned for simplifying complex architectures, fostering platform reuse for financial use cases, and building robust Monitoring and Governance solutions, including foundation/fine-tuned models served with vLLM.  
* **Impactful Technical & Business Advisor:** Strategic technical leader and trusted advisor to cross-functional teams and C-suite stakeholders, with significant impact in Financial Services, Healthcare, and Life Sciences domains.  
* **Passion for AI Transformation:** Passionate about mentoring teams, solving high-impact technical challenges, and championing AI-first transformation at an enterprise scale.

**TECHNICAL EXPERTISE:**  
**Diagramming tools:** Lucid Chart, Visio, Lean IX (APM)  
**Programming Languages**: Python, Java, Shell scripting, SQL  
**Cloud Computing Platform**: AWS, GCP, Azure  
**Containerization:** Kubernetes(EKS, AKS, GKS) , OCP(Openshift Container Platform)  
**Databases-SQL/NOSQL:** Snowflake, AWS RDS, MongoDB, Neo4j, AWS Neptune, AWS Redshift, PostgreSQL  
**Vector DB:** ChromaDB, pgVector, Opensearch, Qdrant  
**CI/CD:** GitHub, Jenkins(groovy scripting), Nexus, JFrog   
**ETL Tools:** Informatica Powercenter, Ab Initio  
**ML Frameworks**: Spark, Dask, PyTorch, scikit-learn  
**Responsible AI:** Model Governance, Explainability Frameworks 

**PROFESSIONAL EXPERIENCE**

**Discover Financial Services(5+ yrs.) \- Domain: Banking and Finance**

**Job Titles:**   
**Expert Application Architect   								January 2024 \- Present**  
**Principal Application Architect 								January 2022 \- December 2023**  
**Lead Software Engineer (Full Stack) 							December 2020 \- January 2022**

* **Designed and deployed an enterprise-scale Generative AI RAG chatbot** over internal architecture repositories, delivering **measurable productivity improvements** by reducing friction in accessing critical technical knowledge.  
* Conducted comprehensive experimentation across **diverse RAG architectures, fine-tuning models, embedding dimensions**, **prompt strategies, and vector databases** to determine the most effective end-to-end system design.  
* **Architected and spearheaded the development of a comprehensive enterprise AI/ML and Generative AI Decisioning Platform**, streamlining the model lifecycle and significantly reducing time-to-deliver for models and strategies by **80%**.  
* **Engineered highly scalable, resilient, and secure cloud-native microservice architectures** with reusable patterns, supporting diverse model serving use cases, including offline, real-time (on-demand) scoring, and **real-time LLM inference via vLLM**.  
* **Re-architected the Decisioning development workbench to enhance functionalities for memory and process-intensive models, enabling GPU acceleration** for advanced model development and training.  
* **Designed and implemented core platform capabilities enabling a seamless experience for Data Scientists** across the entire model life cycle, from training and **prompt engineering** to **LLM fine-tuning** and robust deployment.  
* Optimized container and resource utilization by designing a **user-requirement-driven infrastructure recommendation engine** resulting in **\~65% cost savings.**  
* **Led and mentored** multiple product development teams **(6+ teams, 30+ engineers)**, fostering best practices in design, development, deployment, and integration of complex AI/ML products   
* Built **production-ready data Data and ML pipeline frameworks** which helped in accelerating the entire MLOps process.  
* **Architected end-to-end deployment pipelines**, ensuring streamlined and automated delivery of AI/ML solutions.  
* **Partnered with Data Science teams** to successfully deploy at least **30+ AI/ML models(supporting all line of businesses)** into production via the established framework  
* **Designed and developed reusable libraries** leveraging distributed frameworks, significantly enhancing feature generation capabilities for various models increasing the efficiency of teams by 20%.  
* Established key metrics for model governance and facilitated their collection, ensuring robust oversight and performance tracking within the platform.  
* Designed and developed **a secured, reliable, and scalable framework** by integrating **Vault, AWS IAM, and security tokens** with OpenShift Container Platform (OCP) and Kubernetes principles.  
* Established model governance metrics (model drift, feature drift, and model score explainability) and implemented them in production.  
* Presented the vision, Roadmaps Overarching design strategy and technical solutions to executive leadership across the domains.

**Deloitte Consulting(3 yrs.) \- Domain: HealthCare and LifeSciences**

**Job Titles:**   
**Project Delivery Specialist	  							August 2020 \- December 2020**  
**Project Delivery Senior Analyst	  							December 2017- August 2020**

* **Led a team of 30+ on-shore and off-shore engineers, delivering high-impact technical solutions to Deloitte’s leading Healthcare and Life Sciences clients.**  
* **Provided strategic architecture redesigns leveraging Databricks on Azure, significantly accelerating clients' batch and real-time data processing jobs by 50%.**  
* **Developed and deployed a dynamic framework enabling seamless submission of memory-intensive jobs (e.g., Spark) to managed Kubernetes clusters (EKS, AKS, GKS) across multi-cloud environments (AWS, GCP, Azure) based on job parameters.**  
* **Built and optimized enterprise** Big Data systems using **AWS EMR** and other **distributed processing tools**.  
* Orchestrated **AWS services (Textract, Comprehend Medical)** to develop advanced data extraction frameworks for clinical and life sciences data.  
* **Successfully established complex Ontology relations** across diverse data sources through extensive research on drug databases, enhancing data discoverability and integration.  
* Integrated **AWS Lex** to apply **Natural Language Processing (NLP)** for front-end web application text inputs, facilitating **dynamic data retrieval** from **AWS Neptune**.  
* Developed **robust NLP engines** to process and extract critical insights from clinical text fields.  
* Designed and developed a **full-stack system utilizing SparQL queries to access Neptune databases**, delivering interactive insights via a dynamic frontend dashboard.  
* Consistently delivered innovative solutions by strategically selecting and implementing the most suitable technologies and tools to address complex business challenges.  
* **Recognized with several accolades for adeptly managing time-sensitive impediments and challenges within a fast-paced Agile environment**, successfully building and migrating new and existing applications to production.

**Wipro Technologies (6 yrs.) \- Domain: Banking and Finance, Energy and Natural Resources**

**Job Titles:**   
**Senior Software Engineer	  							December 2015- December 2017**  
**Student Computer Applicant (Software Engineer) 					June 2011- December 2015**

* **Served as a Technical Lead, managing a team of 20 engineers** in the design and implementation of complex data solutions.  
* **Built robust enterprise data pipelines** for extraction, cleaning, and transformation using big data technologies such as Hadoop, MapReduce, Pig, Hive, and Apache Spark.  
* **Designed and established enterprise cloud Data Warehouses** leveraging AWS RedShift and Snowflake.  
* Developed advanced data processing techniques on the AWS platform, utilizing services like CloudFormation Templates (CFTs), Lambda, SNS, ELK (Elasticsearch, Logstash, Kibana), EC2, and S3.  
* **Orchestrated the migration of data pipelines from legacy ETL tools (Ab Initio, Informatica, Apache NiFi) to cloud platforms**, delivering a unified enterprise solution framework for both on-premise and cloud systems.  
* **Automated the entire infrastructure stack (server creation, termination, and restoration) using Chef**, significantly improving operational efficiency by reducing manual errors and deployment time by 70%.   
* Integrated and managed applications across a combination of traditional and real-time databases.  
* Received client commendations for delivering skilled presentations on agile product delivery demos.  
* **Bridged multiple Data Warehouse applications with other critical platforms and tools**, including SAP BI, Salesforce, Informatica PowerCenter, Informatica MDM, and Informatica Data Quality.  
* **Optimized high CPU usage jobs across various tech stacks**, providing more efficient solutions.   
* Received **Pagati awards** for driving Continuous Improvement (CI) initiatives that **reduce manual efforts and processing time by \~80% (saving one engineer time per day)**. 

**EDUCATION & CERTIFICATIONS**

**Master of Sciences, Software Engineering    		January 2012 – December 2015**  
Birla Institute of Technology and Sciences, Pilani, Rajasthan, India 

**Bachelor of Sciences, Computer Sciences                 	June 2008 – March 2011**  
Acharya Nagarjuna University, Guntur, AP, India 

**Certifications:**

* Certified TOGAF Enterprise Architecture Foundation \- Active   
* Certified Kubernetes Application Developer(CKAD) \- Active  
* AWS Certified BigData Specialist \- Expired  
* AWS Certified Developer Associate \- Expired  
* Informatica Powercenter Certified Professional \- Expired

**Industry Impact:**

* Presented at various internal and external forums on the importance of platforms in data and AI ecosystems.  
* Proficient in communicating complex technical concepts to non-technical leadership in a clear and effective manner.  
* Experienced in building, scaling, and optimizing ML systems and data pipelines for production environments.

